#TODO: Load and check against corrections.json and change species
data$art <- str_to_title(data$art)
corrections <- read_json(correction_file)
incorrect_names <- names(corrections)
total_bats <-nrow(data)
for( i in 1:total_bats){
if( name %in% incorrect_names){
data$art[i] <- corrections[[name]]
}
}
data
}
rm(dummy)
rm(i)
rm(corrections)
cleanup_species_names(data_clean)
cleanup_species_names <-function(data, correction_file="corrections.json"){
#TODO: Load and check against corrections.json and change species
data$art <- str_to_title(data$art)
corrections <- read_json(correction_file)
incorrect_names <- names(corrections)
total_bats <-nrow(data)
for( i in 1:total_bats){
name <- data$art[i]
if( name %in% incorrect_names){
data$art[i] <- corrections[[name]]
}
}
data
}
cleanup_species_names(data_clean)
data_names <- cleanup_species_names(data_clean)
unique(data_names$art)
data <- cleanup_column_names(data)
corrections <- read_json(correction_file)
corrections <- read_json("corrections.json")
corrections
corrections[["?"]]
data <- cleanup_column_names(data)
data_clean <- unify_columns(data)
data <- read_xlsx("goholm2023.xlsx")
cleanup_column_names <- function(data){
# Change the column names of a dataframe to snake case and then change the
# more problematic column names.
data <- data %>%
select(-c("autoklassat_som", "vem",
"skriv_bokstaven_h_for_hjalp", "validering"))
data <- data %>%
clean_names()
data
}
data <- cleanup_column_names(data)
data <- read_xlsx("goholm2023.xlsx")
rm(list=ls())
data <- read_xlsx("goholm2023.xlsx")
cleanup_column_names <- function(data){
# Change the column names of a dataframe to snake case and then change the
# more problematic column names.
data <- data %>%
select(-c("autoklassat_som", "vem",
"skriv_bokstaven_h_for_hjalp", "validering"))
data <- data %>%
clean_names()
data
}
cleanup_species_names <-function(data, correction_file="corrections.json"){
#TODO: Load and check against corrections.json and change species
data$art <- str_to_title(data$art)
corrections <- read_json(correction_file)
incorrect_names <- names(corrections)
total_bats <-nrow(data)
for( i in 1:total_bats){
name <- data$art[i]
if( name %in% incorrect_names){
data$art[i] <- corrections[[name]]
}
}
data
}
# Combines the art_1/2/3 columns into one without including empty rows from 2
# and 3
unify_columns <- function(data){
# TODO: Make this prettier and more scaleable by putting df's in a list
data_new <- data %>%
select(-c("art_2", "art_3"))
data_spec_2 <- data %>%
select(-c("art_1", "art_3"))
data_spec_3 <- data %>%
select(-c("art_1", "art_2"))
# Removes empty rows and then append the result to data_new
data_spec_2 <- data_spec_2[!is.na(data_spec_2$art_2),]
data_spec_3 <- data_spec_3[!is.na(data_spec_3$art_3),]
names(data_spec_2) <- names(data_new)
names(data_spec_3) <- names(data_new)
data_new <- bind_rows(data_new, data_spec_2)
data_new <- bind_rows(data_new, data_spec_3)
data_new <- data_new %>%
rename(art = art_1)
data_new
}
data <- cleanup_column_names(data)
names(data)
cleanup_column_names <- function(data){
# Change the column names of a dataframe to snake case and then change the
# more problematic column names.
data <- data %>%
select(-c("Autoklassat som", "Vem",
"skriv bokstaven h för hjälp", "Validering?"))
data <- data %>%
clean_names()
data
}
data <- cleanup_column_names(data)
data_clean <- unify_columns(data)
corrections <- read_json(correction_file)
incorrect_names <- names(corrections)
corrections <- read_json("corrections.json")
incorrect_names <- names(corrections)
total_bats <-nrow(data)
incorrect_names
data_clean$art[1]
data_clean$art[500]
data_clean$art <- str_to_title(data_clean$art)
data_clean$art[500]
data_clean$art[500] %in% incorrect_names
unique(data_clean$art)
data_clean$art[500] <- "Bajs"
data_clean$art[500] %in% incorrect_names
incorrect_names
data_clean$art[500]
data_clean$art[500] %in% incorrect_names
data_clean$art[500] <- "Chiroptera"
data_clean$art[500] %in% incorrect_names
for( i in 1:10){
name <- data$art[i]
print(name)
if( name %in% incorrect_names){
#data$art[i] <- corrections[[name]]
FALSE
}
}
for( i in 1:10){
name <- data_clean$art[i]
print(name)
if( name %in% incorrect_names){
#data$art[i] <- corrections[[name]]
FALSE
}
}
for( i in 1:total_bats){
name <- data$art[i]
if( name %in% incorrect_names){
data_clean$art[i] <- corrections[[name]]
}
}
View(data_clean)
unique(data_clean$art)
for( i in 1:total_bats){
name <- data_clean$art[i]
if( name %in% incorrect_names){
data_clean$art[i] <- corrections[[name]]
}
}
unique(data_clean$art)
corrections <- read_json("corrections.json")
corrections <- read_json("corrections.json")
for( i in 1:total_bats){
name <- data_clean$art[i]
if( name %in% incorrect_names){
data_clean$art[i] <- corrections[[name]]
}
}
unique(data_clean$art)
corrections <- read_json("corrections.json")
incorrect_names <- names(corrections)
incorrect_names
data_clean$art[1] <- "?"
data_clean$art[500] %in% incorrect_names
data_clean$art[1] %in% incorrect_names
for( i in 1:total_bats){
name <- data_clean$art[i]
if( name %in% incorrect_names){
data_clean$art[i] <- corrections[[name]]
}
}
data_clean$art[1]
unique(data_clean$art)
corrections <- read_json("corrections.json")
incorrect_names <- names(corrections)
incorrect_names
unique(data_clean$art)
data_clean$art[1]
data_clean$art[1] <- "?"
data_clean$art[1]
data_clean$art[1] %in% incorrect_names
for( i in 1:total_bats){
name <- data_clean$art[i]
if( name %in% incorrect_names){
data_clean$art[i] <- corrections[[name]]
}
}
data_clean$art[1]
unique(data_clean$art)
data_clean[6778:6780]
data_clean[6778:6780,]
data_clean[6788:6793,]
cleanup_species_names <-function(data, correction_file="corrections.json"){
#Checks species name against corrections.json and change species
data$art <- str_to_title(data$art)
corrections <- read_json(correction_file)
incorrect_names <- names(corrections)
total_bats <-nrow(data)
for( i in 1:total_bats){
name <- data$art[i]
if( name %in% incorrect_names){
data$art[i] <- corrections[[name]]
}
}
data
}
data_clean <- unify_columns(data)
unique(data_clean$art)
data_names <- cleanup_species_names(data_clean)
data_names <- cleanup_species_names(data_names)
unique(data_names$art)
source("./cleanup_functions.R")
str(data_names)
as.POSIXct(data_names$date_time[1], tz=Sys.timezone())
paste0(data_names$date_time[1],":00")
t = paste0(data_names$date_time[1],":00")
as.POSIXct(t, tz=Sys.timezone())
t = paste0(data_names$date_time[1],":00")
as.POSIXct(t, tz=Sys.timezone())
as.POSIXct(data_names$date_time[1], format="%Y%m%d %H:%M", tz=Sys.timezone())
as.POSIXct(data_names$date_time[1], format="%Y%m%d %H:%M", tz="GMT+1")
t<- as.POSIXct(data_names$date_time[1], format="%Y%m%d %H:%M", tz=Sys.timezone())
t
format(t, format = "%H")
format(t, format = "%H") > 20
format(t, format = "%H") < 20
t - format(1, format = "%H")
t - 3600
if( format(t, format = "%H") > 8 ){
print("Bajs")
}
format(t, format = "%H")
if( as.integer(format(t, format = "%H")) > 8 ){
print("Bajs")
}
format(t, format("%Y%m%D"))
format(t, format("%Y-%m-%D"))
format(t, format("%y-%m-%D"))
format(t, format("%Y-%m-%d"))
set_correct_date <- function(datetime, hour= 11){
current_hour <- format(datetime, format = "%H") %>%
as.integer()
if(current_hour < hour){
datetime <- datetime - (hour * 3600)
}
date <- format(datetime, format("%Y%m%d"))
date
}
set_correct_date(t)
t
t<- as.POSIXct("2023-05-08 10:30:00", format="%Y%m%d %H:%M", tz="GMT")
set_correct_date(t)
t<- as.POSIXct("2023-05-08 10:30", format="%Y%m%d %H:%M", tz="GMT")
set_correct_date(t)
t<- as.POSIXct(data_names$date_time[1487], format="%Y%m%d %H:%M", tz=Sys.timezone())
t
set_correct_date(t)
lapply(data$date_time, set_correct_date)
data$date_time <-
as.POSIXct(data_names$date_time,
format="%Y%m%d %H:%M",
tz="GMT+1")
data_names$date_time <-
as.POSIXct(data_names$date_time,
format="%Y%m%d %H:%M",
tz="GMT+1")
lapply(data_names$date_time, set_correct_date)
data_names[1000]
data_names[1000,]
correct_dates <- function(data){
data$date_time <-
as.POSIXct(data$date_time,
format="%Y%m%d %H:%M",
tz="GMT+1")
data_names$date_time <- lapply(data$date_time, set_correct_date)
}
data_names[1188,]
data_raw <- read_xlsx("goholm2023.xlsx")
data <- cleanup_column_names(data_raw)
data_clean <- unify_columns(data)
data_names <- cleanup_species_names(data_clean)
data_dates <- correct_dates(date_names)
data_dates <- correct_dates(data_names)
require(janitor)
require(dplyr)
require(tidyr)
require(readxl)
require(stringr) #To be able to change entries to title case
require(jsonlite)
source("./cleanup_functions.R")
main <- function(){
# Load the data file
data_raw <- read_xlsx("goholm2023.xlsx")
# Change columns to snake case and drop unused columns
data <- cleanup_columns(data_raw)
# Convert to long format based on species columns
data_clean <- unify_columns(data)
# Correct species entries to standardized entries
#TODO: Increase functionality so that it checks against accepted and known
#erroneous values, lists unfamiliar values, and asks you if you want to stop.
data_names <- cleanup_species_names(data_clean)
# Change morning times to previous date, and drop timestamp from datetime.
data_dates <- correct_dates(data_names)
data_dates
#TODO: Export a copy of current dataset for use in Artportalen
#TODO: Clean out question mark entries and spread dataset to count columns
#TODO: Connect to SMHI-API and get mean weather values for the night
}
data <- main()
str(data)
data
main <- function(){
# Load the data file
data_raw <- read_xlsx("goholm2023.xlsx")
# Change columns to snake case and drop unused columns
data <- cleanup_columns(data_raw)
# Convert to long format based on species columns
data_clean <- unify_columns(data)
# Correct species entries to standardized entries
#TODO: Increase functionality so that it checks against accepted and known
#erroneous values, lists unfamiliar values, and asks you if you want to stop.
data_names <- cleanup_species_names(data_clean)
# Change morning times to previous date, and drop timestamp from datetime.
data_dates <- correct_dates(data_names)
#TODO: Export a copy of current dataset for use in Artportalen
#TODO: Clean out question mark entries and spread dataset to count columns
#TODO: Connect to SMHI-API and get mean weather values for the night
data_dates
}
data <- main()
data
data_file <- main()
data_file
data_file <- main()
data_file
main()
# Load the data file
data_raw <- read_xlsx("goholm2023.xlsx")
# Change columns to snake case and drop unused columns
data <- cleanup_columns(data_raw)
# Convert to long format based on species columns
data_clean <- unify_columns(data)
# Correct species entries to standardized entries
#TODO: Increase functionality so that it checks against accepted and known
#erroneous values, lists unfamiliar values, and asks you if you want to stop.
data_names <- cleanup_species_names(data_clean)
# Change morning times to previous date, and drop timestamp from datetime.
data_dates <- correct_dates(data_names)
#TODO: Connect to SMHI-API and get mean weather values for the night
data_dates
source("./cleanup_functions.R")
# Change morning times to previous date, and drop timestamp from datetime.
data_dates <- correct_dates(data_names)
#TODO: Connect to SMHI-API and get mean weather values for the night
data_dates
#TODO: Connect to SMHI-API and get mean weather values for the night
data_dates %>% head()
#TODO: Connect to SMHI-API and get mean weather values for the night
data_dates$date_time
source("./cleanup_functions.R")
# Change morning times to previous date, and drop timestamp from datetime.
data_dates <- correct_dates(data_names)
#TODO: Connect to SMHI-API and get mean weather values for the night
data_dates$date_time
#TODO: Connect to SMHI-API and get mean weather values for the night
data_dates %>% head()
require(writexl)
?writexl
str_extract("Ppyg?", ".?")
str_extract("Ppyg?", ".?.")
str_extract("Ppyg?", ".\?")
str_extract("Ppyg?", "./?")
str_extract("Ppyg?", ".\\?")
str_extract("Ppyg?", "\\?")
str_extract("Ppyg?", ".\\?")
str_extract("Ppyg?", regex(".\\?"))
str_extract("Ppyg", regex("\\?"))
str_extract("Ppyg", regex("\\?"))
str_extract("Ppyg", "\\?")
str_extract("Ppyg?", "\\?")
?replace
replace("Fish", 'F','D')
replace("Fish", 'D','F')
substr('Fish', 2)
substr("Fish", 1, length('Fish')-1)
substr("Fish", 1, nchar('Fish')-1)
#TODO: Clean out question marks from species entries
for( i in 1:nrow(data_dates)){
curr_species <- data_dates$art[i]
if( curr_species == '???'){
next
}
if( !is.na(str_extract(curr_species, "\\?"))){
data_dates$art[i] <- substr(curr_species, 1, nchar(curr_species)-1)
}
}
#TODO: Clean out question marks from species entries
for( i in 1:nrow(data_dates)){
curr_species <- data_dates$art[i]
if( is.na(curr_species) | curr_species == '???'){
next
}
if( !is.na(str_extract(curr_species, "\\?"))){
data_dates$art[i] <- substr(curr_species, 1, nchar(curr_species)-1)
}
}
unique(data_dates$art)
# Change morning times to previous date, and drop timestamp from datetime.
data_dates <- correct_dates(data_names)
unique(data_dates$art)
#TODO: Clean out question marks from species entries
data_certain <- remove_uncertain_data(data_dates)
source("./cleanup_functions.R")
#TODO: Clean out question marks from species entries
data_certain <- remove_uncertain_data(data_dates)
source("./cleanup_functions.R")
#TODO: Clean out question marks from species entries
data_certain <- remove_uncertain_data(data_dates)
unique(data_certain$art)
data_certain
#TODO: Clean out question marks from species entries
data_certain <- remove_uncertain_data(data_dates)
#TODO: Clean out question marks from species entries
data_certain <- remove_uncertain_data(data_dates)
data_certain
source("./cleanup_functions.R")
#TODO: Clean out question marks from species entries
data_certain <- remove_uncertain_data(data_dates)
unique(data_certain$art)
names(data_certain)
#TODO: Spread the data so that it counts the species
data_certain %>%
count(date_time, art) %>%
pivot_wider(names_from = art, values_from = n, values_fill = 0)
seq(as.Date("1910/1/1"), as.Date("1999/1/1"), "years")
seq(as.Date("1910/1/1"), as.Date("1910/1/5"), "days")
seq(as.Date("2023/3/1"), as.Date("2023/12/15"), "days")
seq(as.Date("2023/3/1"), as.Date("2023/12/15"), "days") %>%
data.frame()
time_series <- seq(as.Date("2023/3/1"), as.Date("2023/12/15"), "days")
data_clean %>% names()
data_clean$date_time
data_certain$date_time
str_replace_all("2023-12-01","/","")
str_replace_all("2023-12-01","-","")
str_replace_all(c("2023-12-01", "2023-12-01"),"-","")
?Map
seq(as.Date("2023/3/1"), as.Date("2023/12/15"), "days") %>%
str_replace_all("-","")
seq(as.Date("2023/3/1"), as.Date("2023/12/15"), "days") %>%
str_replace_all("-","") %>%
as.data.frame()
time_series <- seq(as.Date("2023/3/1"), as.Date("2023/12/15"), "days") %>%
str_replace_all("-","") %>%
as.data.frame()
names(time_series) <- "date"
names(time_series)
time_series %>% head()
?join_by
names(data_certain)
sales <- tibble(
id = c(1L, 1L, 1L, 2L, 2L),
sale_date = as.Date(c("2018-12-31", "2019-01-02", "2019-01-05", "2019-01-04", "2019-01-01"))
)
sales
promos <- tibble(
id = c(1L, 1L, 2L),
promo_date = as.Date(c("2019-01-01", "2019-01-05", "2019-01-02"))
)
promos
by <- join_by(id, sale_date == promo_date)
by
left_join(sales, promos, by)
left_join(sales, promos)
promos
sales
promos <- promos[2:3,]
promos
left_join(sales, promos)
time_series <- seq(as.Date("2023/3/1"), as.Date("2023/12/15"), "days") %>%
str_replace_all("-","") %>%
as.data.frame()
names(time_series) <- "date_time"
date_count <- data %>%
count(date_time, art) %>%
pivot_wider(names_from = art, values_from = n, values_fill = 0)
date_count <- data_certain %>%
count(date_time, art) %>%
pivot_wider(names_from = art, values_from = n, values_fill = 0)
left_join(time_series, date_count)
date_count
left_join(time_series, date_count)[60,]
left_join(time_series, date_count)[69,]
source("./cleanup_functions.R")
# Spread the data so that it counts the species occurences per night.
data_wide <- spread_by_date(data_certain)
data_wide
data_wide[69,]
